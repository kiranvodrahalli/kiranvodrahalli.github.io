---
layout: page
title: about
redirect_from:
  - ""
---


<!-- example of the message class
<p class="message">
  My name is Kiran Vodrahalli. 
</p>
-->

<!-- add picture --> 
![image-title-here]({{site.baseurl}}/public/kiran-profile.jpg){:class="img-responsive" .element height="30%" width="30%"} 

### Update

I am currently looking for postdoctoral and research positions starting in Fall 2022; I am interested in both applied and theoretical (or some mix thereof) research in machine learning (see my <a href="{{ site.baseurl }}/about/cv.pdf" title="cv"> [CV] </a> ). 
I am interested in focusing on one of the following topics in my next role: 

#### Memory Bounded and Resource Efficient Learning
* memory-bounded and resource-efficient bandit/reinforcement learning
* memory-bounded and resource-efficient language modeling and understanding
* memory-bounded and resource-efficient representation learning

#### Learning and Algorithmic Game Theory (see [The Platform Design Problem](https://arxiv.org/abs/2009.06117))
* game theoretic analysis of bi-level environment design \\
and applications to internet economics and reinforcement learning
* manipulation of learning agents and strategic behavior of learning agents in response to manipulation
* data collection mechanisms and privacy/fairness considerations
* new concepts of equilibria in learning in games and multi-agent learning settings
* incentives and strategic behavior in machine learning

#### Fusing Logic and Learning (see [Learning and Planning with Logical Automata](https://link.springer.com/article/10.1007/s10514-021-09993-6))
* outfitting large blackbox generative models/policies with interpretable controls
* interpretable machine learning via interactive learning
* learning the "grammar" of action sequences (ex: learning the rules of the road)


Please [email me](mailto:kiran.vodrahalli@columbia.edu) if you think we might have some aligned interests!


### Currently...

I am a [Computer Science](http://www.cs.columbia.edu/) Ph.D. student at Columbia University, focusing on theoretical computer science, with particular interest in machine learning, algorithms, and statistics. My thesis topic is resource-efficient (sparse/ low-memory / low-rank) machine learning. I am extremely fortunate to \\
be advised by [Professor Daniel Hsu](http://www.cs.columbia.edu/~djhsu/) and [Professor Alex Andoni](http://www.mit.edu/~andoni/). I have been supported by an NSF Graduate Research Fellowship. 

I am also a part-time student researcher at Google Brain in Fall 2021.

Affiliations:
* [Columbia CS Theory](http://theory.cs.columbia.edu/) 
* [Columbia Machine Learning](https://ml.cs.columbia.edu/)
* [Google Brain Research](https://research.google/teams/brain/)

Other Info: 
* [Email](mailto:kiran.vodrahalli@columbia.edu)
* [Twitter](https://twitter.com/kiranvodrahalli)
* [Github](https://github.com/kiranvodrahalli)
* [GoodReads](https://www.goodreads.com/review/list/6132224)
* [LinkedIn](https://www.linkedin.com/in/kiranvodrahalli/)
* [Quora](https://www.quora.com/profile/Kiran-Vodrahalli)

For more details, either check out this website or see my <a href="{{ site.baseurl }}/about/cv.pdf" title="cv"> [CV] </a>. 


---

### Research Interests


My primary area of research is theoretical computer science: in particular, provably resource-efficient algorithms for fitting statistical models in various settings ("algorithmic statistics", "foundations of machine learning", "learning theory", etc.). Some of my work in this direction has skewed in the direction of giving computationally efficient, low sample complexity algorithms for learning functions with sparse descriptions. I am also interested in algorithms and optimization theory. I have also worked on applications of machine learning in several fields, including neuroscience, natural language understanding, economics, and robotics. Currently, I am particularly focused on designing algorithms and proving lower bounds for memory-bounded learning and optimization problems. I am also working on applying ideas from machine learning (online learning, learning in games, reinforcement learning) and bi-level optimization to understand computational and statistical issues associated with the economics of the online firm, as well as associated privacy, ethics, and fairness concerns (see my recent paper [The Platform Design Problem](https://arxiv.org/abs/2009.06117)). 


---

### Previously...

In Summer 2021 I was a research intern at Google Brain, where I worked on principled resource-efficient methods for training deep neural networks.

In Summer 2019 I visited the Simons Institute at Berkeley for the [Foundations of Deep Learning](https://simons.berkeley.edu/programs/dl2019) program. 

I graduated from [Princeton](https://www.princeton.edu) with an A.B. Mathematics degree with honors in 2016 and an M.S.E. in Computer Science in 2017, where I was lucky to have [Professor Sanjeev Arora](http://www.cs.princeton.edu/~arora/) and [Professor Ken Norman](https://psych.princeton.edu/person/kenneth-norman) as thesis advisors. I was a member of Sanjeev Arora's [Unsupervised Learning Group](http://unsupervised.cs.princeton.edu/members.html), where I studied provable methods for machine learning (also a part of [NLP @ Princeton](http://nlp.cs.princeton.edu/) and [ML Theory @Princeton](https://mltheory.cs.princeton.edu/people/)), in particular focusing on natural language understanding. I was also a member of Ken Norman's [Computational Memory Lab](http://compmem.princeton.edu/lab-people/) at the [Princeton Neuroscience Institute](http://pni.princeton.edu), where I applied machine learning to fMRI analysis methods. 


