<!DOCTYPE html>
<html lang="en">

  <head>

   
   <!--
     redirect users to the https version of the website.
     but: only check when on the production domain, as set in _config.yml.
    -->
   <script type="text/javascript">
     var enforce = "kiranvodrahalli.github.io";
     if ((enforce == window.location.host) && (window.location.protocol != "https:"))
       window.location = window.location.toString().replace(/^http:/, "https:");
   </script>
   

  <!-- EB Garamond Font --> 
  <link href='https://fonts.googleapis.com/css?family=EB+Garamond' rel='stylesheet' type='text/css'>
  <meta charset="UTF-8">
  <link href="https://gmpg.org/xfn/11" rel="profile">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>
    
      notes || representing things
    
  </title>

  <!-- MathJax -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({ 
      TeX: { 
        extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "bbox.js", "color.js", "enclose.js"] 
      },
      unicode: {
        fonts: "STIXGeneral, 'Arial Unicode MS'"
      }
    });
  </script>
  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>



  <!-- CSS -->
  <link rel="stylesheet" href="/styles.css">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="57x57" href="/public/favicomatic/apple-touch-icon-57x57.png" />
  <link rel="apple-touch-icon-precomposed" sizes="114x114" href="/public/favicomatic/apple-touch-icon-114x114.png" />
  <link rel="apple-touch-icon-precomposed" sizes="72x72" href="/public/favicomatic/apple-touch-icon-72x72.png" />
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/favicomatic/apple-touch-icon-144x144.png" />
  <link rel="apple-touch-icon-precomposed" sizes="60x60" href="/public/favicomatic/apple-touch-icon-60x60.png" />
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="/public/favicomatic/apple-touch-icon-120x120.png" />
  <link rel="apple-touch-icon-precomposed" sizes="76x76" href="/public/favicomatic/apple-touch-icon-76x76.png" />
  <link rel="apple-touch-icon-precomposed" sizes="152x152" href="/public/favicomatic/apple-touch-icon-152x152.png" />
  <link rel="icon" type="image/png" href="/public/favicomatic/favicon-196x196.png" sizes="196x196" />
  <link rel="icon" type="image/png" href="/public/favicomatic/favicon-96x96.png" sizes="96x96" />
  <link rel="icon" type="image/png" href="/public/favicomatic/favicon-32x32.png" sizes="32x32" />
  <link rel="icon" type="image/png" href="/public/favicomatic/favicon-16x16.png" sizes="16x16" />
  <link rel="icon" type="image/png" href="/public/favicomatic/favicon-128.png" sizes="128x128" />
  <link rel="shortcut icon" type="image/png" href="/public/favicomatic/favicon.ico" />

  <!-- RSS -->
  <link rel="alternate" type="application/atom+xml" title="representing things" href="/atom.xml">
</head>


  <body>

    <div class="container content">
      <header class="masthead">
        <h3 class="masthead-title">
          <a href="/" title="Home">||representing things||</a>
          <small>[kiran's theoryblog]</small>
        </h3>
        <a href="/about" title="about">{about}</a>
        <a href="/projects" title="projects">{projects}</a>
        <a href="/notes" title="notes">{notes}</a>
        <a href="/contact" title="contact">{contact}</a>
      </header>

      <main>
        <article class="page">
  <h1 class="page-title">notes</h1>
  <!-- example of the message class
<p class="message">
  My name is Kiran Vodrahalli. 
</p>
-->

<p>As a general note, please contact me if you find errors in my notes so that I may fix them.</p>

<h2>Talks</h2>

<p>I attend various academic talks and seminars and sometimes scribe them.</p>

<h3>Santosh Vempala on the Complexity of Detecting Planted Solutions <a href = "/notes/planted-graph-vempala.pdf" title="vempala">[pdf]</a></h3>

<p>Professor Santosh Vempala of Georgia Tech gave a talk on showing that for statistical algorithms (e.g. PCA, EM, and so on), solving planted clique and planted \(k\)-SAT is at least exponential time in the size of the input.</p>

<h3>Amir Ali Ahmadi on Optimizing over Nonnegative Polynomials <a href= "/notes/ahmadi.pdf" title="ahmadi">[pdf]</a></h3>

<p>Professor Amir Ali Ahmadi from Princeton spoke about formulating convex optimization problems in terms of finding nonnegative polynomials to provably optimize various problems in controls, dynamical systems, and machine learning, improving upon the time complexity of previous sum-of-squares SDP relaxations. He also describes robust dynamics optimization (RDO), a framework for solving optimization problems over a set of points defined by a dynamical system.</p>

<h3>Francisco Pereira on Decoding Generic Representations of fMRI <a href= "/notes/pereira-words.pdf" title="pereira-words">[pdf]</a></h3>

<p>Dr. Francisco Pereira from Siemens talked about his work using sentences and pictures to localize fMRI voxels for representing semantic content in brains.</p>

<h3>Elad Hazan on Simulated Annealing and Interior Point Methods <a href= "/notes/hazan-annealing.pdf" title="hazan-annealing">[pdf]</a></h3>

<p>Professor Elad Hazan gave a talk to Princeton&#39;s Algorithm-ML reading group on a result demonstrating the existence of a universal barrier function for interior point methods in the membership oracle model of convex optimization. This barrier is related to the heuristic simulated annealing approach often taken in non-convex optimization. </p>

<h3>Dana Lahat on Joint Independent Subspace Analysis and Blind Source Separation <a href= "/notes/joint-ISA.pdf" title="joint-ISA">[pdf]</a></h3>

<p>This talk gives an overview of blind source separation with various statistical independence assumptions, generalizing ICA to learning subspaces of low-rank instead of just rank \(1\) subspaces.</p>

<h3>Barbara Engelhardt on Bayesian Structured Sparsity Using Gaussian Fields <a href= "/notes/engelhardt_pni.pdf" title="engelhardt-pni-notes">[pdf]</a></h3>

<p>Professor Barbara Engelhardt gave a talk on her work on identifying associations between SNPs and phenotypes with sparse machine learning methods. She also spoke on how these methods can be translated to brain studies.</p>

<h3>Dimitris Bertsimas on Statistics and Machine Learning from a Modern Optimization Lens <a href= "/notes/SML_modern_optimization.pdf" title="MIOnotes">[pdf]</a></h3>

<p>Professor Dimitris Bertsimas from MIT gave a talk on using the mixed integer-programming (MIO) framework as a new lens through which to view machine learning, statistics, and optimization problems. </p>

<h3>Sébastien Bubeck on Optimal Regret Bounds for the General Convex Multi-Armed Bandit Setting <a href= "/notes/bubeck_talk.pdf" title="bubecknotes">[pdf]</a></h3>

<p>Dr. Sébastien Bubeck from Microsoft Research gave a talk to the Alg-ML reading group on his \(2015\) result on a tight minimax regret bound for the setting of general convex bandit optimization in dimensions greater than one. </p>

<h3>Han Liu on Nonparametric Graphical Models <a href= "/notes/han_liu_pni.pdf" title="hanliunotes">[pdf]</a></h3>

<p>Professor Han Liu from Princeton gave an overview of his recent research and theoretical results on nonparametric graphical models.</p>

<h3>Mehryar Mohri on Deep Boosting <a href= "/notes/deep_boosting.pdf" title="mohrinotes">[pdf]</a></h3>

<p>Professor Mehryar Mohri from the Courant Institute speaks about ensemble boosting methods that take advantage of complex hypothesis classes along with the use of standard simple weak learners. He also presents an interpretation of boosting as truly being about model selection.</p>

<h3>Percy Liang on Learning Hidden Computational Processes <a href= "/notes/percy_liang_talk.pdf" title="percyliangnotes">[pdf]</a></h3>

<p>Professor Percy Liang from Stanford discussed approaches to solving question-answering tasks on a new hand-built dataset. </p>

<h3>Young Kun Ko on the Hardness of Sparse PCA  <a href= "/notes/braverman_sparse_PCA.pdf" title="sparsepcanotes">[pdf]</a></h3>

<p>This talk summarizing two results on sparse principal components analysis was given to the Braverman Reading Group at Princeton.</p>

<h3>Ben Recht on Perceptron Learning and Stability</h3>

<p>Professor Ben Recht from Berkeley discussed a notion of stability applied to stochastic gradient descent to explain why it reaches the same local optima in the nonconvex setting. Notes still to be added.</p>

<h3>Tom Griffiths on Rationality, Heuristics, and the Cost of Computation <a href= "/notes/griffiths_rationality_heuristics_computationcost_berkeley.pdf" title="griffithsnotes">[pdf]</a></h3>

<p>Professor Tom Griffiths from Berkeley discussed a notion of rationality which takes into account computation time as a resource. From his perspective, we can explain why some decision-making procedures which appear to be suboptimal are actually optimal from a sparse-resource respective. </p>

<h3>Anna Choromanska on Optimization for Large-Scale Machine Learning <a href= "/notes/choromanska_deeplearning.pdf" title="choromanskanotes">[pdf]</a></h3>

<p>Dr. Anna Choromanska from the Courant Institute talks about new learning algorithms for decision trees and spin-glass interpretations of deep learning. </p>

<h3>Richard Socher on Dynamic Memory Networks <a href= "/notes/socher_last_lec_224d.pdf" title="socherdmnnotes">[pdf]</a></h3>

<p>Dr. Richard Socher&#39;s last lecture for the Stanford class 224d (Deep Learning for NLP) was on a recent paper by his startup, Metamind. He spoke about using a novel deep learning architecture to solve question-and-answer problems, and also about how to generalize all of NLP to a question-and-answer framework with this kind of model. </p>

<h2>Classes</h2>

<h3>APC 529: Coding Theory and Random Graphs</h3>

<p>I will post my revised scribe notes for this course at the end of January 2016.</p>

<h3>ELE 535: Pattern Recognition and Machine Learning</h3>

<p>I will post my scribe notes for this course at the end of January 2016. </p>

<h3>COS 511: Theoretical Machine Learning</h3>

<p>I took <a href= "http://www.cs.princeton.edu/courses/archive/spring15/cos511/" title= "cos511"> scribe notes</a> for most lectures of this class in its Spring 2015 iteration.  </p>

<h3>COS 510: Programming Languages</h3>

<p>I will post my scribe notes on the Curry-Howard equivalence of programs and proofs here. </p>

<h3>APC 486: Transmission and Compression of Information</h3>

<p>Here are <a href= "/notes/apc486_kiran_scribe_notes.pdf" title="apc486notes">my scribe notes</a> on probabilistic source models.</p>

</article> 



      </main>

      <footer class="footer">
        <small>
          &copy; <time datetime="2015-11-16T18:23:22-05:00">2015</time>. All rights reserved.
        </small>
      </footer>
    </div>

  </body>
</html>

