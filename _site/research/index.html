<!DOCTYPE html>
<html lang="en">

  <head>

   
   <!--
     redirect users to the https version of the website.
     but: only check when on the production domain, as set in _config.yml.
    -->
   <script type="text/javascript">
     var enforce = "kiranvodrahalli.github.io";
     if ((enforce == window.location.host) && (window.location.protocol != "https:"))
       window.location = window.location.toString().replace(/^http:/, "https:");
   </script>
   

  <!-- EB Garamond Font --> 
  <link href='https://fonts.googleapis.com/css?family=EB+Garamond:400,100,100italic,300,300italic,400italic,500,500italic,700,700italic,900italic,900' rel='stylesheet' type='text/css'>
  <meta charset="UTF-8">
  <link href="https://gmpg.org/xfn/11" rel="profile"> 

  <!-- Roboto Font --> 
  <link href="https://fonts.googleapis.com/css?family=Roboto:400,100,100italic,300,300italic,400italic,500,500italic,700,700italic,900italic,900" rel='stylesheet' type='text/css'>
  <meta charset="UTF-8">
  <link href="https://gmpg.org/xfn/11" rel="profile">

    <!-- Gelasio Font --> 
  <link href="https://fonts.googleapis.com/css?family=Gelasio:400,100,100italic,300,300italic,400italic,500,500italic,700,700italic,900italic,900" rel='stylesheet' type='text/css'>
  <meta charset="UTF-8">
  <link href="https://gmpg.org/xfn/11" rel="profile">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>
    
      research || exponentially surprised
    
  </title>

  <!-- MathJax -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({ 
      TeX: { 
        extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "bbox.js", "color.js", "enclose.js"] 
      },
      unicode: {
        fonts: "STIXGeneral, 'Arial Unicode MS'"
      }
    });
  </script>
  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>



  <!-- CSS -->
  <link rel="stylesheet" href="/styles.css">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="57x57" href="/public/favicomatic/apple-touch-icon-57x57.png" />
  <link rel="apple-touch-icon-precomposed" sizes="114x114" href="/public/favicomatic/apple-touch-icon-114x114.png" />
  <link rel="apple-touch-icon-precomposed" sizes="72x72" href="/public/favicomatic/apple-touch-icon-72x72.png" />
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/favicomatic/apple-touch-icon-144x144.png" />
  <link rel="apple-touch-icon-precomposed" sizes="60x60" href="/public/favicomatic/apple-touch-icon-60x60.png" />
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="/public/favicomatic/apple-touch-icon-120x120.png" />
  <link rel="apple-touch-icon-precomposed" sizes="76x76" href="/public/favicomatic/apple-touch-icon-76x76.png" />
  <link rel="apple-touch-icon-precomposed" sizes="152x152" href="/public/favicomatic/apple-touch-icon-152x152.png" />
  <link rel="icon" type="image/png" href="/public/favicomatic/favicon-196x196.png" sizes="196x196" />
  <link rel="icon" type="image/png" href="/public/favicomatic/favicon-96x96.png" sizes="96x96" />
  <link rel="icon" type="image/png" href="/public/favicomatic/favicon-32x32.png" sizes="32x32" />
  <link rel="icon" type="image/png" href="/public/favicomatic/favicon-16x16.png" sizes="16x16" />
  <link rel="icon" type="image/png" href="/public/favicomatic/favicon-128.png" sizes="128x128" />
  <link rel="shortcut icon" type="image/png" href="/public/favicomatic/favicon.ico" />

  <!-- RSS -->
  <link rel="alternate" type="application/atom+xml" title="exponentially surprised" href="/atom.xml">
</head>


  <body>

    <div class="container content">
      <header class="masthead">
        <h3 class="masthead-title">
          <font size="8">Kiran Vodrahalli</font> 
        </h3>
        <!-- is <a href="/" title="Home">||exponentially surprised||</a>
          <small>[2<sup>H</sup> Theory Blog]</small> 
        -->
        <a href="/about" title="about">{about}</a>
        <a href="/research" title="research">{research}</a>
        <a href="/talks" title="talks">{talks}</a>
        <a href="/blog" title="blog">{blog}</a>
        <a href="/archive" title="archive">{archive}</a>
        <a href="/teaching" title="teaching">{teaching}</a>
        <a href="/notes" title="notes">{notes}</a>
        <a href="/links" title="links">{links}</a>
        <a href="/press" title="press">{press}</a>
        <!-- <div align="left">
          <img src="/professional_headshot.jpg" alt="kiran_pic" height="400">
        </div> -->
      </header>

      <main>
        <article class="page">
  <h1 class="page-title">research</h1>
  <!-- example of the message class
<p class="message">
  My name is Kiran Vodrahalli. 
</p>
-->

<ul id="markdown-toc">
  <li><a href="#conference-and-journal-publications" id="markdown-toc-conference-and-journal-publications">Conference and Journal Publications</a>    <ul>
      <li><a href="#all-publications" id="markdown-toc-all-publications">All Publications</a></li>
    </ul>
  </li>
  <li><a href="#workshop-publications" id="markdown-toc-workshop-publications">Workshop Publications</a></li>
  <li><a href="#technical-reports-and-theses" id="markdown-toc-technical-reports-and-theses">Technical Reports and Theses</a></li>
  <li><a href="#code" id="markdown-toc-code">Code</a>    <ul>
      <li><a href="#coding-projects" id="markdown-toc-coding-projects">Coding Projects</a></li>
    </ul>
  </li>
</ul>

<p>Also see my <a href="https://scholar.google.com/citations?user=fHYRTzMAAAAJ&amp;hl=en">Google Scholar</a> and <a href="https://arxiv.org/search/?searchtype=author&amp;query=Vodrahalli%2C+K">ArXiv</a> pages (these may be incomplete).</p>

<p>Some of my papers have authors listed in alphabetical order (standard for theory papers).<br />
Therefore, I use * to denote co-authorship to avoid confusion.</p>

<hr />

<!--
## Preprints

---

-->

<h2 id="conference-and-journal-publications">Conference and Journal Publications</h2>

<p><button onclick="window.location.href='/research/research-topic/index.html#conference-and-journal-publications';">Sort papers by topic </button></p>

<h3 id="all-publications">All Publications</h3>

<p><span class="blue bold">[C9]</span> <span class="papertitle">The Platform Design Problem</span>.<br />
<span class="tab">Christos Papadimitriou*, <strong>Kiran Vodrahalli</strong>*, Mihalis Yannakakis*.</span><br />
<span class="tab">WINE Conference on Internet and Web Economics, December 2021. Oral Presentation.</span><br />
<span class="tab"><a href="/research/publications/wine21.pdf" title="PDP"> [pdf] </a> <a href="https://arxiv.org/abs/2009.06117" title="pdp_arxiv"> [arXiv] </a> <a href="/posters/ec21-poster.pdf" title="ec21-poster"> [poster] </a></span></p>

<p><span class="orange bold">[J2]</span> <span class="papertitle">Learning and Planning with Logical Automata</span>.<br /> 
<span class="tab">Brandon Araki, <strong>Kiran Vodrahalli</strong>, Thomas Leech, Cristian-Ioan Vasile, Mark Donahue, Daniela Rus.</span><br />
<span class="tab">Autonomous Robots, August 2021.</span><br /> 
<span class="tab"><a href="/research/publications/autonomousrobots21.pdf" title="autonomousrobots21"> [pdf] </a> <a href="https://link.springer.com/article/10.1007/s10514-021-09993-6" title="springer"> [journal] </a></span></p>

<p><span class="blue bold">[C8]</span> <span class="papertitle">The Logical Options Framework</span>.<br /> 
<span class="tab">Brandon Araki, Xiao Li, <strong>Kiran Vodrahalli</strong>, Jonathan DeCastro, J. Micah Fry, Daniela Rus.</span><br />
<span class="tab">ICML International Conference on Machine Learning, July 2021. Long Oral Presentation and Poster.</span><br /> 
<span class="tab"><a href="/research/publications/icml21.pdf" title="icml21"> [pdf] </a> <a href="http://proceedings.mlr.press/v139/araki21a.html" title="icml2021"> [mlr press] </a> <a href="/posters/icml21-poster.pdf" title="icml21poster"> [poster] </a> <a href="https://icml.cc/virtual/2021/poster/9379" title="icml21poster"> [icml] </a></span></p>

<p><span class="blue bold">[C7]</span> <span class="papertitle">Deep Bayesian Nonparametric Learning of Rules and Plans from Demonstrations with a Learned Automaton Prior</span>.<br /> 
<span class="tab">Brandon Araki, <strong>Kiran Vodrahalli</strong>, Thomas Leech, Cristian-Ioan Vasile, Mark Donahue, Daniela Rus.</span><br />
<span class="tab">AAAI Conference on Artificial Intelligence, February 2020. Spotlight Presentation and Poster.</span><br /> 
<span class="tab"><a href="/research/publications/aaai20.pdf" title="aaai20"> [pdf] </a> <a href="/research/publications/aaai20_supp.pdf" title="aaai20_supp"> [supplement] </a><a href="https://aaai.org/Conferences/AAAI-20/" title="aaai2020"> [conference] </a> <a href="/posters/aaai20-poster.pdf" title="aaai20poster"> [poster] </a></span></p>

<p><span class="blue bold">[C6]</span> <span class="papertitle">Privacy Accounting and Quality Control in the Sage Differentially Private ML Platform</span>.<br /> 
<span class="tab">Mathias Lécuyer, Riley Spahn, <strong>Kiran Vodrahalli</strong>, Roxana Geambasu, Daniel Hsu.</span><br /> 
<span class="tab">Symposium on Operation Systems Principles, October 2019. Oral Presentation.</span><br /> 
<span class="tab"><a href="/research/publications/sosp19.pdf" title="sosp19pdf"> [pdf] </a> <a href="https://arxiv.org/abs/1909.01502" title="sosp19_arxiv"> [arXiv] </a> <a href="https://sosp19.rcs.uwaterloo.ca/program.html" title="sosp19"> [conference] </a><a href="/posters/sosp19-poster.pdf" title="sosp19poster"> [poster] </a></span></p>

<p><span class="blue bold">[C5]</span> <span class="papertitle">Learning to Plan with Logical Automata</span>.<br /> 
<span class="tab">Brandon Araki*, <strong>Kiran Vodrahalli</strong>*, Thomas Leech, Cristian-Ioan Vasile, Mark Donahue, Daniela Rus.</span><br />
<span class="tab">Robotics: Science and Systems, June 2019. Spotlight Presentation and Poster.</span><br />
<span class="tab"><a href="/research/publications/rss19.pdf" title="rss19"> [pdf] </a> <a href="http://www.roboticsconference.org/" title="rss"> [conference] </a> <a href="/posters/rss2019-poster.pdf" title="rss19poster"> [poster] </a></span></p>

<p><span class="blue bold">[C4]</span> <span class="papertitle">Attribute-Efficient Learning of Monomials over Highly-Correlated Variables</span>.<br />
<span class="tab">Alex Andoni*, Rishabh Dudeja*, Daniel Hsu*, <strong>Kiran Vodrahalli</strong>*.</span><br />
<span class="tab">Algorithmic Learning Theory, March 2019. Oral Presentation.</span><br />
<span class="tab"><a href="/research/publications/alt19.pdf" title="alt19"> [pdf] </a> <a href="http://proceedings.mlr.press/v98/andoni19a.html" title="alt19pmlr"> [pmlr] </a> <a href="http://alt2019.algorithmiclearningtheory.org/accepted-papers/" title="alt"> [conference] </a> <a href="/posters/Columbia-Data-Science-Poster-2018-Vodrahalli.pdf" title="columbia-fods18"> [poster] </a></span></p>

<p><span class="blue bold">[C3]</span> <span class="papertitle">A Large Self-Annotated Corpus for Sarcasm</span>.<br /> 
<span class="tab">Mikhail Khodak, Nikunj Saunshi, <strong>Kiran Vodrahalli</strong>.</span><br /> 
<span class="tab">Language Resources and Evaluation, May 2018. Poster.</span><br /> 
<span class="tab"><a href="/research/publications/lrec18.pdf" title="lrec18"> [pdf] </a> <a href="http://www.lrec-conf.org/proceedings/lrec2018/pdf/160.pdf" title="lrec18"> [conference] </a> <a href="https://arxiv.org/abs/1704.05579" title="lrec18_arxiv"> [arXiv] </a> <a href="http://nlp.cs.princeton.edu/SARC/">[dataset]</a> <a href="https://github.com/NLPrinceton/SARC">[code]</a></span></p>

<p><span class="blue bold">[C2]</span> <span class="papertitle">A Compressed Sensing View of Unsupervised Text Embeddings, Bag-of-n-Grams, and LSTMs</span>.<br /> 
<span class="tab">Sanjeev Arora*, Mikhail Khodak*, Nikunj Saunshi*, <strong>Kiran Vodrahalli</strong>*.</span><br /> 
<span class="tab">International Conference on Learning Representations, April 2018. Poster.</span><br /> 
<span class="tab"><a href="/research/publications/iclr18.pdf" title="iclr18"> [pdf] </a> <a href="http://www.offconvex.org/2018/06/25/textembeddings/">[blog]</a> <a href="/research/publications/iclr18_abstract.pdf" title="iclr18_abstract"> [abstract] </a> <a href="https://openreview.net/forum?id=B1e5ef-C-" title="iclr18"> [conference] </a> <a href="/posters/iclr18_poster.pdf" title="iclr18"> [poster] </a> <a href="https://https//github.com/NLPrinceton/text_embedding">[embedding code]</a> <a href="https://https//github.com/NLPrinceton/sparse_recovery">[recovery code]</a> <a href="http://nlp.cs.princeton.edu/DisC/">[word vectors]</a></span></p>

<p><span class="blue bold">[C1]</span> <span class="papertitle">A Temporal Decay Model for Mapping between fMRI and Natural Language Annotations</span>.<br /> 
<span class="tab"><strong>Kiran Vodrahalli</strong>, Cathy Chen, Viola Mocz, Christopher Baldassano, Uri Hasson, Sanjeev Arora, Kenneth A. Norman.</span><br /> 
<span class="tab">Cognitive Computational Neuroscience, September 2017. Poster.</span><br /> 
<span class="tab"><a href="/research/publications/ccn17.pdf" title="ccn17"> [pdf] </a> <a href="https://www2.securecms.com/CCNeuro/docs-0/591d7d2668ed3f3154cce90a.pdf" title="ccn17"> [conference] </a> <a href="/posters/ccn17_poster.pdf" title="ccn17"> [poster] </a> <a href="https://github.com/kiranvodrahalli/fMRI_Text_maps_NI">[code]</a></span></p>

<p><span class="orange bold">[J1]</span> <span class="papertitle">Mapping between fMRI responses to movies and their natural language annotations</span>.<br /> 
<span class="tab"><strong>Kiran Vodrahalli</strong>, Po-Hsuan Chen, Yingyu Liang, Christopher Baldassano, Janice Chen,</span><br />
<span class="tab">Christopher Honey, Uri Hasson, Peter Ramadge, Kenneth A. Norman, Sanjeev Arora.</span><br /> 
<span class="tab">Neuroimage, June 2017.</span><br /> 
<span class="tab"><a href="/research/publications/neuroimage17.pdf" title="neuroimage17"> [pdf] </a> <a href="http://www.sciencedirect.com/science/article/pii/S1053811917305128" title="neuroimage"> [journal] </a> <a href="https://arxiv.org/abs/1610.03914" title="neuroimage_arxiv"> [arXiv] </a> <a href="https://github.com/kiranvodrahalli/fMRI_Text_maps_NI">[code]</a></span></p>

<hr />

<h2 id="workshop-publications">Workshop Publications</h2>

<p><span class="green bold">[W6]</span> <span class="papertitle">The Platform Design Problem</span>.<br />
<span class="tab">Christos Papadimitriou*, <strong>Kiran Vodrahalli</strong>*, Mihalis Yannakakis*.</span><br />
<span class="tab"><a href="https://netecon21.gametheory.online/home">EC 2021 NetEcon Workshop</a>, July 2021. Oral Presentation and Poster.</span><br />
<span class="tab">(Note: same work as WINE ‘21 conference publication).</span><br />
<span class="tab"><a href="/research/publications/platform-design-problem.pdf" title="PDP"> [pdf] </a> <a href="https://arxiv.org/abs/2009.06117" title="pdp_arxiv"> [arXiv] </a> <a href="/posters/ec21-poster.pdf" title="ec21-poster"> [poster] </a></span></p>

<p><span class="green bold">[W5]</span> <span class="papertitle">Learning to Plan with Logical Automata</span>.<br /> 
<span class="tab">Brandon Araki*, <strong>Kiran Vodrahalli</strong>*, Cristian-Ioan Vasile, Daniela Rus.</span><br /> 
<span class="tab"><a href="https://sites.google.com/view/infer2control-nips2018">NeurIPS 2018 Workshop on Infer2Control</a>, December 2018. Oral Presentation and Poster.</span><br /> 
<span class="tab">(Note: same work as RSS ‘19 conference publication).</span><br />
<span class="tab"><a href="/research/workshops/neurips18_infer2control.pdf" title="lvin_neurips18"> [pdf] </a> <a href="/talks/Learning-to-Plan-with-Logical-Automata.pdf" title="infer2control-neurips2018-slides"> [slides] </a> <a href="/posters/lvin-infer2control-neurips18-poster.pdf" title="infer2control-neurips2018-poster"> [poster] </a></span></p>

<p><span class="green bold">[W4]</span> <span class="papertitle">A Compressed Sensing View of Unsupervised Text Embeddings, Bag-of-n-Grams, and LSTMs</span>.<br /> 
<span class="tab">Sanjeev Arora*, Mikhail Khodak*, Nikunj Saunshi*, <strong>Kiran Vodrahalli</strong>*.</span><br /> 
<span class="tab"><a href="https://sites.google.com/site/repl4nlp2018/home">ACL Workshop on Representation Learning for NLP</a>, July 2018. Poster.</span><br />
<span class="tab">(Note: same work as ICLR ‘18 conference publication).</span></p>

<p><span class="green bold">[W3]</span> <span class="papertitle">A Compressed Sensing View of Unsupervised Text Embeddings, Bag-of-n-Grams, and LSTMs</span>.<br />
<span class="tab">Sanjeev Arora*, Mikhail Khodak*, Nikunj Saunshi*, <strong>Kiran Vodrahalli</strong>*.</span><br /> 
<span class="tab"><a href="https://sites.google.com/site/deeplearningtheory/">ICML Workshop on Theory of Deep Learning</a>, July 2018. Oral Presentation and Poster.</span><br /> 
<span class="tab">(Note: same work as ICLR ‘18 conference publication).</span></p>

<p><span class="green bold">[W2]</span> <span class="papertitle">Mapping between Natural Movie fMRI Responses and Word-Sequence Representations</span>.<br /> 
<span class="tab"><strong>Kiran Vodrahalli</strong>, Po-Hsuan Chen, Yingyu Liang, Janice Chen, Esther Yong,</span><br />
<span class="tab">Christopher Honey, Peter J. Ramadge, Kenneth A. Norman, Sanjeev Arora.</span><br /> 
<span class="tab"><a href="https://arxiv.org/abs/1701.01437">NeurIPS Workshop on Representation Learning in Artificial and Biological Neural Networks</a>,</span><br />
<span class="tab">Dec 2016. Oral Presentation and Poster.</span><br /> 
<span class="tab">(Note: Earlier version of NeuroImage ‘17 journal publication).</span><br />
<span class="tab"><a href="/talks/NIPS2016_kiranvodrahalli_presentation.pdf" title="ssrm_neurips16"> [slides] </a> <a href="/posters/nips16_MLINI_poster.pdf" title="ssrm_neurips16"> [poster] </a> <a href="https://github.com/kiranvodrahalli/fMRI_Text_maps_NI">[code]</a></span></p>

<p><span class="green bold">[W1]</span> <span class="papertitle">A Semantic Shared Response Model</span>.<br /> 
<span class="tab"><strong>Kiran Vodrahalli</strong>, Po-Hsuan Chen, Janice Chen, Esther Yong, Christopher Honey, </span><br />
<span class="tab">Peter J. Ramadge, Kenneth A. Norman, Sanjeev Arora.</span><br /> 
<span class="tab"> <a href="http://ttic.uchicago.edu/~wwang5/ICML2016_MVRL/" title="MVRL"> ICML Workshop on Multi-view Representation Learning </a>, Jun 2016. Oral Presentation and Poster.</span><br /> 
<span class="tab">(Note: Earlier version of NeuroImage ‘17 journal publication).</span><br />
<span class="tab"><a href="/research/workshops/icml16_mvrl.pdf" title="ssrm_icml16"> [pdf] </a><a href="/talks/A_Semantic_Shared_Response_Model.pdf" title="srm_icml16"> [slides] </a> <a href="/posters/icml16_MVRL_poster.pdf" title="ssrm_icml16"> [poster] </a> <a href="https://github.com/kiranvodrahalli/fMRI_Text_maps_NI">[code]</a></span></p>

<hr />

<h2 id="technical-reports-and-theses">Technical Reports and Theses</h2>

<p><span class="grey bold">[T11]</span> <span class="papertitle">Temporally Dependent Mappings Between fMRI Responses and Natural Language Descriptions of Natural Stimuli</span>. COS MSE Thesis (May 2017). Advised by Sanjeev Arora and Ken Norman. <a href="/research/theses/MSE_COS_thesis.pdf" title="mse_thesis"> [pdf] </a> <a href="https://github.com/kiranvodrahalli/fMRI_Text_maps_NI">[code]</a></p>

<p><span class="grey bold">[T10]</span> <span class="papertitle">Low-dimensional Representations of Semantic Context in Language and the Brain</span>. MAT AB Thesis (May 2016). Advised by Sanjeev Arora and Ken Norman. <a href="/research/theses/ugrad_MAT_thesis.pdf" title="ab_thesis"> [pdf] </a> <a href="https://github.com/kiranvodrahalli/fMRI_Text_maps_NI">[code]</a></p>

<p><span class="grey bold">[T9]</span> <span class="papertitle">Learning the Optimal Step Size for Gradient Descent on Convex Quadratics</span>. Poster for NYAS ML Symposium 2020. <br />
<span class="tab">Alex Andoni*, Daniel Hsu*, Tim Roughgarden*, <strong>Kiran Vodrahalli</strong>*.</span><a href="/posters/nyasml2020-poster.pdf" title="nyasml-2020"> [poster] </a><br /></p>

<p><span class="grey bold">[T8]</span> <span class="papertitle">Can Simple Assembly Algorithms Compute Robust, High-Dimensional Means?</span>. COMS 6998-06 Project (Fall 2018). Advised by Christos Papadimitriou. <a href="/research/reports/computation-and-brain-paper.pdf" title="6998-06"> [pdf] </a></p>

<p><span class="grey bold">[T7]</span> <span class="papertitle">An Efficient General Algorithm for Interactive Clustering</span>. COMS 6998-04 Project (Fall 2017). Advised by Daniel Hsu. <a href="/research/reports/efficient_interactive_clustering.pdf" title="6998-04"> [pdf] </a></p>

<p><span class="grey bold">[T6]</span> <span class="papertitle">Sparse, Low-dimensional and Multimodal Representations of Time Series for Mind-Reading</span>. COS 513 Project (Fall 2015). With Lydia Liu and Niranjani Prasad. Advised by Barbara Engelhardt. <a href="/research/reports/cos513paper.pdf" title="cos513"> [pdf] </a> <a href="/research/reports/cos513/" title="cos513blog"> [blog] </a></p>

<!-- This work is joint with Lydia Liu (Princeton ORFE '17) and Niranjani Prasad (Grad Student, Princeton CS Department). We investigated the application of sparse canonical correlation analysis (sCCA) as a tool for creating low-dimensional combined representations of EEG/MEG and fMRI brain data. We used two experiments to demonstrate that our low-dimensional representation retained useful information by testing on two datasets: One was a paired EEG-fMRI time series oddball response dataset and the other was a paired MEG-fMRI time series dataset of subjects looking at various types of objects (<a href = "http://people.csail.mit.edu/rmcichy/publication_pdfs/Cichy_et_al_NN_2014.pdf" title="cichy2014"> Resolving human object recognition in space and time (Cichy et. al, 2014) </a>). In both instances we outperformed other traditional methods of low-dimensional representation, including PCA and ICA. We submitted our work as a project for <a href= "http://www.cs.princeton.edu/~bee/courses/cos513.html" title= "cos513web"> COS 513: Foundations of Probabilistic Modeling</a>, taught by Prof. Barbara Engelhardt. -->

<p><span class="grey bold">[T5]</span> <span class="papertitle">Learning Shifting Communities Online in the Adversarial Block Model</span>. APC 529 Project (Fall 2015). Advised by Emmanuel Abbe. <a href="/research/reports/apc529paper.pdf" title="apc529"> [pdf] </a></p>

<!--
perhaps put this in a different section, e.g. surveys section? (papers which are more surveys than original work, like ramon class, etc.)

For the final project in APC 529: Coding Theory and Random Graphs, taught by Professor Emmanuel Abbé, I analyzed the Stochastic Block Model (SBM) from the perpsective of online optimization, making use of recent results in the online learning of eigenvectors and the exact recovery setting of the SBM to build a framework for learning communities as they change over time with guaranteed regret bounds. -->

<p><span class="grey bold">[T4]</span> <span class="papertitle">Solving Word Analogies With Convex Optimization</span>. COS 511 Project (Spring 2015). Advised by Elad Hazan. <a href="/research/reports/cos511paper.pdf" title="cos511"> [pdf] </a> <a href="https://github.com/kiranvodrahalli/convex_word_vecs">[code]</a></p>

<!-- My final project for <a href= "http://www.cs.princeton.edu/courses/archive/spring15/cos511/" title= "cos511"> COS 511: Theoretical Machine Learning</a> investigated convex loss functions for learning word vectors to solve word analogy problems. Word analogies are of the form king:man :: queen:woman. Given three of the four words, the task is to correctly identify the fourth. Traditionally, this problem is approached in the unsupervised setting and texts are used to learn which words are most relevant. Word vectors, word representations in high-dimensional real space, are often used (particularly in the past few years) as a solution to the analogy problem via dot-product queries, an approach which has recently been validated by <a href= "http://arxiv.org/abs/1502.03520" title= "random_walks_semantic_space"> [Arora et al (2015)]</a>. I formulated a convex loss with which to train word vectors that in principle keeps the spirit of the dot product query intuition, implemented AdaGrad <a href= "http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf" title= "AdaGrad"> [Duchi et al (2011)]</a>, and trained on word pairs. -->

<p><span class="grey bold">[T3]</span> <span class="papertitle">Comparing Hebbian Semantic Vectors Across Language</span>. NEU 330 Project (Spring 2015). Advised by Ken Norman. <a href="/research/reports/neu330paper.pdf" title="neu330"> [pdf] </a> <a href="https://github.com/kiranvodrahalli/hebb_vectors">[code]</a></p>

<!-- My final project for NEU 330, Connectionist Models, focused on building Hebbian neural network word vector models for parallel corpora, with the purpose of evaluating the word vectors based on how similarly the word vectors for translation pairs behaved in their respective corpora. The principle I held throughout the project was simply that changing language should essentially not effect the representation of a word/concept in a high-dimensional vector space. I both proposed methods of evaluation and made use of previously used metrics to evaluate the 9 models considered. The texts used to form the word vectors were Harry Potter and The Philosopher's Stone and its French counterpart. -->

<p><span class="grey bold">[T2]</span> <span class="papertitle">Noun Compounds in Semantic Quad-Space</span>. Junior Independent Work (Fall 2014). Advised by Christiane Fellbaum. <a href="/research/reports/iw2014paper.pdf" title="iw2014"> [pdf] </a> <a href="https://github.com/kiranvodrahalli/quad_space">[code]</a></p>

<!-- My junior independent work with Dr. Christiane Fellbaum aimed to build a model for analyzing the similarity between noun compounds, which consist of a modifier noun and a head noun, like "life force." Accurate parsing can greatly improve question answering systems for various knowledge bases. For example, medical QA systems must correctly parse noun compounds like "human colon cancer line" to answer questions accurately. I looked at several approaches to analyzing the similarity of noun compounds and built a vector space model of noun compounds, inspired by the papers of Turney <a href= "http://arxiv.org/abs/1309.4035" title="Domain_and_function"> [Turney 2013]</a> and Fyshe <a href= "http://www.aclweb.org/anthology/W13-3510" title="fyshe_paper"> [Fyshe et al 2013] </a>. I extended Turney's dual-space model to a quad space model and ran it on two large corpora, <a href= "http://corpus.byu.edu/coca/" title="coca"> COCA </a>  and <a href= "http://corpus.byu.edu/glowbe/" title="glowbe"> GloWbE </a>. I then evaluated the results by comparing to a ground truth provided by Mechanical Turk workers. -->

<p><span class="grey bold">[T1]</span> <span class="papertitle">Estimating Trending Twitter Topics With Count-Min Sketch</span>. COS 521 Project (Fall 2014). With Evan Miller and Albert Lee. Advised by Sanjeev Arora. <a href="/research/reports/cos521paper.pdf" title="cos521"> [pdf] </a> <a href="https://github.com/kiranvodrahalli/cos521">[code]</a></p>

<!-- My final project for <a href= "http://www.cs.princeton.edu/courses/archive/fall14/cos521/" title= "cos521"> COS 521: Advanced Algorithms</a> was joint with Evan Miller (Princeton COS '16) and Albert Lee (Princeton COS '16). We attempted to solve the following problem: Given a time series of Twitter data, can we infer current trending topics on Twitter while appropriately discounting past tweets using a sketch-based approach? We tweaked the Hokusai data structure <a href= "http://www.auai.org/uai2012/papers/231.pdf" title= "Hokusai"> [Matusevych et al 2012]</a> and implemented it, then ran experiments on Twitter data. -->

<!-- * Characterizing Intellectual Interests with SVM
In fall 2013, I began working with Professor Sam Wang of Princeton Neuroscience Institute (PNI) on applying machine learning to an intellectual interest survey, which attempts to identify the discipline and intensity of academic interest in survey respondents. The goal of the project was to investigate intellectual interest as a potential phenotypic marker for autism. In order to study whether this hypothesis was plausible, we had survey responses from two groups of people. The Simons Simplex Collection (SSC) dataset is a repository of genetic samples from families where one child is affected with an autism spectrum disorder. We had survey responses from simplex members, the parents of autistic children. The other responses were obtained by polling readers of Professor Wang's political blog. My role in this project was to create a classifier which given a survey response could output a score indicating certainty that the survey respondent had a particular intellectual interest; for instance, the humanities. This project was my first exposure to the difficulty of munging through data and the application of machine learning to problems in cognitive science. The classifier I eventually trained had \\(94\\)% accuracy for determining intellectual interest, making the survey-classifier pair potentially useful as a tool. -->

<hr />

<h2 id="code">Code</h2>

<p>For the code accompanying my research projects, see the links next to each paper or my <a href="https://github.com/kiranvodrahalli">github</a>.</p>

<h3 id="coding-projects">Coding Projects</h3>
<!-- describe coding side projects here later? -->
<p><em>Outershell</em>. <a href="https://github.com/kiranvodrahalli/outershell">[code]</a>
Outershell is a simple hack to enable the bash shell with the full functionality of an iPython shell. The idea was inspired by chat windows with a computational environment: e.g., it would be awesome if one could interactively code with a chat buddy, with the data structures and functions remaining around for indefinite use. Outershell implements this kind of functionality for a single user on a computer. This kind of functionality already kind of exists in the form of the shell or various programs like Emacs and Vim (for power users at least), but Outershell democratizes its accessibility by enabling users to code their functions in Python.</p>


</article> 



      </main>

      <footer class="footer">
        <small>
          &copy; <time datetime="2021-09-26T15:28:44-04:00">2021</time>. All rights reserved.
        </small>
      </footer>
    </div>

  </body>
</html>

