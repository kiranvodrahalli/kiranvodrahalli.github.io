<!DOCTYPE html>
<html lang="en">

  <head>

   
   <!--
     redirect users to the https version of the website.
     but: only check when on the production domain, as set in _config.yml.
    -->
   <script type="text/javascript">
     var enforce = "kiranvodrahalli.github.io";
     if ((enforce == window.location.host) && (window.location.protocol != "https:"))
       window.location = window.location.toString().replace(/^http:/, "https:");
   </script>
   

  <!-- EB Garamond Font --> 
  <link href='https://fonts.googleapis.com/css?family=EB+Garamond' rel='stylesheet' type='text/css'>
  <meta charset="UTF-8">
  <link href="https://gmpg.org/xfn/11" rel="profile">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>
    
      about || exponentially surprised
    
  </title>

  <!-- MathJax -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({ 
      TeX: { 
        extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "bbox.js", "color.js", "enclose.js"] 
      },
      unicode: {
        fonts: "STIXGeneral, 'Arial Unicode MS'"
      }
    });
  </script>
  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>



  <!-- CSS -->
  <link rel="stylesheet" href="/styles.css">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="57x57" href="/public/favicomatic/apple-touch-icon-57x57.png" />
  <link rel="apple-touch-icon-precomposed" sizes="114x114" href="/public/favicomatic/apple-touch-icon-114x114.png" />
  <link rel="apple-touch-icon-precomposed" sizes="72x72" href="/public/favicomatic/apple-touch-icon-72x72.png" />
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/favicomatic/apple-touch-icon-144x144.png" />
  <link rel="apple-touch-icon-precomposed" sizes="60x60" href="/public/favicomatic/apple-touch-icon-60x60.png" />
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="/public/favicomatic/apple-touch-icon-120x120.png" />
  <link rel="apple-touch-icon-precomposed" sizes="76x76" href="/public/favicomatic/apple-touch-icon-76x76.png" />
  <link rel="apple-touch-icon-precomposed" sizes="152x152" href="/public/favicomatic/apple-touch-icon-152x152.png" />
  <link rel="icon" type="image/png" href="/public/favicomatic/favicon-196x196.png" sizes="196x196" />
  <link rel="icon" type="image/png" href="/public/favicomatic/favicon-96x96.png" sizes="96x96" />
  <link rel="icon" type="image/png" href="/public/favicomatic/favicon-32x32.png" sizes="32x32" />
  <link rel="icon" type="image/png" href="/public/favicomatic/favicon-16x16.png" sizes="16x16" />
  <link rel="icon" type="image/png" href="/public/favicomatic/favicon-128.png" sizes="128x128" />
  <link rel="shortcut icon" type="image/png" href="/public/favicomatic/favicon.ico" />

  <!-- RSS -->
  <link rel="alternate" type="application/atom+xml" title="exponentially surprised" href="/atom.xml">
</head>


  <body>

    <div class="container content">
      <header class="masthead">
        <h3 class="masthead-title">
          <font size="8">Kiran Vodrahalli</font> is <a href="/" title="Home">||exponentially surprised||</a>
          <small>[2<sup>H</sup> theoryblog]</small> 
        </h3>
        <a href="/about" title="about">{about}</a>
        <a href="/research" title="research">{research}</a>
        <a href="/talks" title="talks">{talks}</a>
        <a href="/blog" title="blog">{blog}</a>
        <a href="/archive" title="archive">{archive}</a>
        <a href="/teaching" title="teaching">{teaching}</a>
        <a href="/notes" title="notes">{notes}</a>
        <a href="/links" title="links">{links}</a>
        <a href="/press" title="press">{press}</a>
        <!-- <div align="left">
          <img src="/professional_headshot.jpg" alt="kiran_pic" height="400">
        </div> -->
      </header>

      <main>
        <article class="page">
  <h1 class="page-title">about</h1>
  <!-- example of the message class
<p class="message">
  My name is Kiran Vodrahalli. 
</p>
-->

<h3 id="currently">Currently…</h3>

<p>I am a Ph.D. student at Columbia University, focusing on theoretical computer science, with particular interest in machine learning, algorithms, and statistics. I am extremely fortunate to be advised by <a href="http://www.cs.columbia.edu/~djhsu/">Professor Daniel Hsu</a> and <a href="http://www.mit.edu/~andoni/">Professor Alex Andoni</a>. I am supported by an NSF Graduate Research Fellowship.</p>

<p>I am affiliated with the <a href="http://www.cs.columbia.edu/">Computer Science department</a>, particularly the <a href="http://www.cs.columbia.edu/theory/">Theory group</a> and the <a href="http://www.cs.columbia.edu/areas/machine/">Machine learning group</a>, as well as the <a href="http://datascience.columbia.edu/">Data Science Institute</a>. In particular, see the <a href="http://www.columbia.edu/~jw2966/TRIPODS.html">Columbia TRIPODS Institute</a>. 
For more details, either check out this website or see my <a href="/about/cv.pdf" title="cv"> [CV] </a>. My Github repository is located at <a href="https://github.com/kiranvodrahalli" title="github"> https://github.com/kiranvodrahalli </a>. I enjoy reading in my free time — you can check out what books I’ve particularly enjoyed at my <a href="https://www.goodreads.com/review/list/6132224">GoodReads</a> page. My <a href="https://www.linkedin.com/in/kiranvodrahalli/">LinkedIn</a> has some additional miscellaneous information. I have answered a few questions on <a href="https://www.quora.com/profile/Kiran-Vodrahalli">Quora</a>. I prefer to be contacted by email at <a href="mailto:kiran.vodrahalli@columbia.edu">kiran . vodrahalli AT &lt;univ&gt; . edu</a> or by tweet <a href="https://twitter.com/kiranvodrahalli">@kiranvodrahalli</a>.</p>

<hr />

<h3 id="research-interests">Research Interests</h3>

<p>My primary area of research is provable algorithms and models for computational inference and optimization. Many of my interests can be summarized by the phrase ‘‘non-worst-case analysis for machine learning algorithms.’’ I like conditions that constrain the problem space that are easy to check. I believe theory informs practice, and practice informs theory. I am particularly interested in the following broad areas:</p>

<ul>
  <li>Theoretical frameworks for unsupervised learning which allow one to give guarantees on performance</li>
  <li>Identifying general, favorable properties of unsupervised feature representations</li>
  <li>Theoretically justifying generation models</li>
  <li>Compressed sensing and recovery properties of representations</li>
  <li>Identifying and learning over low-dimensional structures (of all sorts, but recently I have focused on various notions of sparsity). In particular, the goal is to give algorithms which achieve sample complexities and computational complexities which depend on the ‘‘low-dimensional’’ part of the structure, rather than the (potentially high-dimensional) ambient space.</li>
  <li>Interactive learning applied to evaluation methodology and learning problem formulation</li>
  <li>Differentially private systems</li>
  <li>Going beyond i.i.d. assumptions: Learning over non-product distributions, etc. I’ve also recently gotten interested in adaptive data analysis and other settings where the training data distribution and the testing data distribution do not satisfy simple properties (like i.i.d.).</li>
  <li>Generalization bounds for models which do not currently have completely satisfactory guarantees (read my lips d-e-e-p l-e-a-r-n-i-n-g). In particular, I am interested in data-dependent bounds on the sample complexity.</li>
  <li>Non-convex optimization with guarantees</li>
  <li>Better characterization of easy-to-check data properties which ensure good statistical/computational efficiency. Also, developing data collection methods to ensure such properties exist in datasets.</li>
  <li>Interactive, game theoretic approaches to data collection</li>
  <li>Alternative algorithms to the scientific method</li>
  <li>Developing better tools for analyzing experiments and performing feature selection</li>
  <li>Highly-structured learning: learning rules and logic in reinforcement learning settings. I am also interested in models which blend rigid structure (like logic) with statistical models.</li>
  <li>Multi-task and meta-learning</li>
  <li>Randomized and approximation algorithms</li>
  <li>Sublinear algorithms (sketching and streaming settings)</li>
  <li>Understanding sequence models: Bridging the gap between HMMs and RNNs.</li>
  <li>Identifying failure modes of learning algorithms and models (e.g., adversarial examples)</li>
</ul>

<p>In applications, I am particularly interested in natural language understanding and neuroscience.</p>

<hr />

<h3 id="previously">Previously…</h3>

<p>Previously, I graduated from <a href="https://www.princeton.edu">Princeton</a> with an A.B. Mathematics degree with honors in 2016 and an M.S.E. in Computer Science in 2017, where I was lucky to have <a href="http://www.cs.princeton.edu/~arora/">Professor Sanjeev Arora</a> and <a href="https://psych.princeton.edu/person/kenneth-norman">Professor Ken Norman</a> as thesis advisors. I was a member of Sanjeev Arora’s <a href="http://unsupervised.cs.princeton.edu/members.html">Unsupervised Learning Group</a>, where I studied provable methods for machine learning, in particular focusing on natural language understanding. I was also a member of Ken Norman’s <a href="http://compmem.princeton.edu/lab-people/">Computational Memory Lab</a> at the <a href="http://pni.princeton.edu">Princeton Neuroscience Institute</a>, where I applied machine learning to fMRI analysis methods.</p>


</article> 



      </main>

      <footer class="footer">
        <small>
          &copy; <time datetime="2018-10-05T17:00:01-04:00">2018</time>. All rights reserved.
        </small>
      </footer>
    </div>

  </body>
</html>

