<!DOCTYPE html>
<html lang="en">

  <head>

   
   <!--
     redirect users to the https version of the website.
     but: only check when on the production domain, as set in _config.yml.
    -->
   <script type="text/javascript">
     var enforce = "kiranvodrahalli.github.io";
     if ((enforce == window.location.host) && (window.location.protocol != "https:"))
       window.location = window.location.toString().replace(/^http:/, "https:");
   </script>
   

  <!-- EB Garamond Font --> 
  <link href='https://fonts.googleapis.com/css?family=EB+Garamond' rel='stylesheet' type='text/css'>
  <meta charset="UTF-8">
  <link href="https://gmpg.org/xfn/11" rel="profile">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>
    
      about || exponentially surprised
    
  </title>

  <!-- MathJax -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({ 
      TeX: { 
        extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "bbox.js", "color.js", "enclose.js"] 
      },
      unicode: {
        fonts: "STIXGeneral, 'Arial Unicode MS'"
      }
    });
  </script>
  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>



  <!-- CSS -->
  <link rel="stylesheet" href="/styles.css">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="57x57" href="/public/favicomatic/apple-touch-icon-57x57.png" />
  <link rel="apple-touch-icon-precomposed" sizes="114x114" href="/public/favicomatic/apple-touch-icon-114x114.png" />
  <link rel="apple-touch-icon-precomposed" sizes="72x72" href="/public/favicomatic/apple-touch-icon-72x72.png" />
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/favicomatic/apple-touch-icon-144x144.png" />
  <link rel="apple-touch-icon-precomposed" sizes="60x60" href="/public/favicomatic/apple-touch-icon-60x60.png" />
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="/public/favicomatic/apple-touch-icon-120x120.png" />
  <link rel="apple-touch-icon-precomposed" sizes="76x76" href="/public/favicomatic/apple-touch-icon-76x76.png" />
  <link rel="apple-touch-icon-precomposed" sizes="152x152" href="/public/favicomatic/apple-touch-icon-152x152.png" />
  <link rel="icon" type="image/png" href="/public/favicomatic/favicon-196x196.png" sizes="196x196" />
  <link rel="icon" type="image/png" href="/public/favicomatic/favicon-96x96.png" sizes="96x96" />
  <link rel="icon" type="image/png" href="/public/favicomatic/favicon-32x32.png" sizes="32x32" />
  <link rel="icon" type="image/png" href="/public/favicomatic/favicon-16x16.png" sizes="16x16" />
  <link rel="icon" type="image/png" href="/public/favicomatic/favicon-128.png" sizes="128x128" />
  <link rel="shortcut icon" type="image/png" href="/public/favicomatic/favicon.ico" />

  <!-- RSS -->
  <link rel="alternate" type="application/atom+xml" title="exponentially surprised" href="/atom.xml">
</head>


  <body>

    <div class="container content">
      <header class="masthead">
        <h3 class="masthead-title">
          <a href="/" title="Home">||exponentially surprised||</a>
          <small>[2<sup>H</sup> theoryblog]</small> 
        </h3>
        <a href="/about" title="about">{about}</a>
        <a href="/projects" title="projects">{projects}</a>
        <a href="/notes" title="notes">{notes}</a>
        <a href="/contact" title="contact">{contact}</a>
        <div align="left">
          <img src="/professional_headshot.jpg" alt="kiran_pic" height="400">
        </div>
      </header>

      <main>
        <article class="page">
  <h1 class="page-title">about</h1>
  <!-- example of the message class
<p class="message">
  My name is Kiran Vodrahalli. 
</p>
-->

<p>I am currently a Ph.D. student at Columbia University, focusing on theoretical computer science, with particular interest in machine learning, algorithms, and statistics. I am extremely fortunate to be advised by <a href="http://www.cs.columbia.edu/~djhsu/">Daniel Hsu</a> and <a href="http://www.mit.edu/~andoni/">Alex Andoni</a>. I am affiliated with the <a href="http://www.cs.columbia.edu/">Computer Science department</a>, particularly the <a href="http://www.cs.columbia.edu/theory/">Theory group</a> and the <a href="http://www.cs.columbia.edu/areas/machine/">Machine learning group</a>, as well as the <a href="http://datascience.columbia.edu/">Data Science Institute</a>.</p>

<p>My primary area of research is provable algorithms and models for computational inference and optimization. A lot of my interests can be summarized by the phrase ``Non-worst-case analysis for machine learning algorithms’’. I tend to prefer using conditions that constrain the problem space that are easy to check. I am also a fan of the notion that theory informs practice, and practice informs theory. I am particularly interested in the following broad areas:</p>

<ul>
  <li>
    <p>Theoretical frameworks for unsupervised learning which allow one to give guarantees on performance</p>
  </li>
  <li>
    <p>Interactive learning applied to evaluation methodology and learning problem formulation</p>
  </li>
  <li>
    <p>Generalization bounds for models which do not currently have completely satisfactory guarantees (read my lips d-e-e-p l-e-a-r-n-i-n-g). In particular, I am interested in data-dependent bounds on the sample complexity.</p>
  </li>
  <li>
    <p>Non-convex optimization with guarantees</p>
  </li>
  <li>
    <p>Better characterization of easy-to-check data properties which ensure good statistical/computational efficiency. Also, developing data collection methods to ensure such properties exist in datasets.</p>
  </li>
  <li>
    <p>Highly-structured learning: learning rules and logic in reinforcement learning settings. I am also interested in models which blend rigid structure (like logic) with statistical models.</p>
  </li>
  <li>
    <p>Understanding sequence models: Bridging the gap between HMMs and RNNs.</p>
  </li>
  <li>
    <p>Identifying and learning over low-dimensional structures (of all sorts, but recently I have focused on various notions of sparsity). In particular, the goal is to give algorithms which achieve sample complexities and computational complexities which depend on the ``low-dimensional’’ part of the structure, rather than the (potentially high-dimensional) ambient space.</p>
  </li>
  <li>
    <p>Identifying failure modes of learning algorithms and models</p>
  </li>
  <li>
    <p>Theoretically justifying generation models</p>
  </li>
</ul>

<p>In applications, I am particularly interested in natural language understanding and neuroscience.</p>

<p>Previously, I graduated from <a href="https://www.princeton.edu">Princeton</a> with an A.B. Mathematics degree with honors in 2016 and an M.S.E. in Computer Science in 2017. I was a member of Sanjeev Arora’s <a href="http://unsupervised.cs.princeton.edu/members.html">Unsupervised Learning Group</a>, where I studied provable methods for machine learning. One applications of particular interest was natural language understanding. I was also a member of Ken Norman’s <a href="http://compmem.princeton.edu/lab-people/">Computational Memory Lab</a> at the <a href="http://pni.princeton.edu">Princeton Neuroscience Institute</a>, where I applied machine learning to fMRI analysis methods.</p>

<p>For more details, either check out this website or see my out-of-date <a href="/about/cv.pdf" title="cv"> curriculum vitae </a>.</p>

</article> 



      </main>

      <footer class="footer">
        <small>
          &copy; <time datetime="2017-12-03T05:20:41-05:00">2017</time>. All rights reserved.
        </small>
      </footer>
    </div>

  </body>
</html>

